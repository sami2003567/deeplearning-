{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 🧠 Deep Learning Practical Assignment (Adult Income Dataset)\n",
        "\n",
        "## 📌 Dataset\n",
        "We will use the **Adult Income dataset** (also known as the Census Income dataset).  \n",
        "The task is to predict whether a person earns **more than $50K/year** based on demographic and employment attributes.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "THxjKfmyG-St"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETxUv-9oGeuT",
        "outputId": "39613be7-8bbe-4b0a-ea6b-7f2f1ce6cb25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/wenruliu/adult-income-dataset?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 652k/652k [00:00<00:00, 80.7MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/wenruliu/adult-income-dataset/versions/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   age  workclass  fnlwgt     education  education-num      marital-status  \\\n",
            "0   25    Private  226802          11th              7       Never-married   \n",
            "1   38    Private   89814       HS-grad              9  Married-civ-spouse   \n",
            "2   28  Local-gov  336951    Assoc-acdm             12  Married-civ-spouse   \n",
            "3   44    Private  160323  Some-college             10  Married-civ-spouse   \n",
            "4   18        NaN  103497  Some-college             10       Never-married   \n",
            "\n",
            "          occupation relationship   race     sex  capital-gain  capital-loss  \\\n",
            "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
            "1    Farming-fishing      Husband  White    Male             0             0   \n",
            "2    Protective-serv      Husband  White    Male             0             0   \n",
            "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
            "4                NaN    Own-child  White  Female             0             0   \n",
            "\n",
            "   hours-per-week native-country  class  \n",
            "0              40  United-States  <=50K  \n",
            "1              50  United-States  <=50K  \n",
            "2              40  United-States   >50K  \n",
            "3              40  United-States   >50K  \n",
            "4              30  United-States  <=50K  \n",
            "(48842, 15)\n"
          ]
        }
      ],
      "source": [
        "# Option 1: Using OpenML via scikit-learn\n",
        "from sklearn.datasets import fetch_openml\n",
        "import pandas as pd\n",
        "\n",
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"wenruliu/adult-income-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# Load dataset from OpenML\n",
        "adult = fetch_openml(name=\"adult\", version=2, as_frame=True)\n",
        "df = adult.frame\n",
        "\n",
        "print(df.head())\n",
        "print(df.shape)  # (48842, 15)\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop(columns=\"class\")\n",
        "y = df[\"class\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 0: Data Preparation\n",
        "1. Load the dataset into a DataFrame.\n",
        "2. Split the data into **training, validation, and test sets**.  \n",
        "   - Suggested: 70% training, 15% validation, 15% test.\n",
        "3. Apply any necessary preprocessing:\n",
        "   - Handle categorical features (encoding).\n",
        "   - Scale numerical features if needed.\n",
        "4. After training your models, always report results on:\n",
        "   - **Training accuracy**\n",
        "   - **Validation accuracy**\n",
        "   - **Test accuracy**\n",
        "5. At the end of the assignment, **compare all methods** across train, validation, and test sets.\n"
      ],
      "metadata": {
        "id": "qqY4sTfrHQF_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a230352d",
        "outputId": "4260ef09-f22c-423c-fa72-48fc2f20f22d"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Split data into training (70%), validation (15%), and test (15%) sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Validation set shape:\", X_val.shape, y_val.shape)\n",
        "print(\"Test set shape:\", X_test.shape, y_test.shape)\n",
        "\n",
        "# Identify categorical and numerical features\n",
        "categorical_features = X.select_dtypes(include=['object', 'category']).columns\n",
        "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# Create preprocessing pipelines for numerical and categorical features\n",
        "numerical_transformer = StandardScaler()\n",
        "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "# Create a column transformer to apply different transformations to different columns\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Apply preprocessing to the data\n",
        "X_train_processed = preprocessor.fit_transform(X_train)\n",
        "X_val_processed = preprocessor.transform(X_val)\n",
        "X_test_processed = preprocessor.transform(X_test)\n",
        "\n",
        "print(\"\\nProcessed Training set shape:\", X_train_processed.shape)\n",
        "print(\"Processed Validation set shape:\", X_val_processed.shape)\n",
        "print(\"Processed Test set shape:\", X_test_processed.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (34189, 14) (34189,)\n",
            "Validation set shape: (7326, 14) (7326,)\n",
            "Test set shape: (7327, 14) (7327,)\n",
            "\n",
            "Processed Training set shape: (34189, 108)\n",
            "Processed Validation set shape: (7326, 108)\n",
            "Processed Test set shape: (7327, 108)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Part 1: Optimizers\n",
        "1. Train the same neural network using:\n",
        "   - Stochastic Gradient Descent (SGD)\n",
        "   - SGD with Momentum\n",
        "   - Adam\n",
        "2. Compare the training and validation accuracy for each optimizer.\n",
        "3. Which optimizer converges the fastest? Which gives the best generalization?\n",
        "4. Explain *why* Adam often performs better than plain SGD.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "LPpltt4ZG3fN"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c364487",
        "outputId": "9d11eb46-d1a0-47fd-ff06-d8eec38310d4"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Define a simple neural network model\n",
        "def build_model():\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Dense(128, activation='relu', input_shape=(X_train_processed.shape[1],)),\n",
        "        keras.layers.Dropout(0.2),\n",
        "        keras.layers.Dense(64, activation='relu'),\n",
        "        keras.layers.Dropout(0.2),\n",
        "        keras.layers.Dense(1, activation='sigmoid') # Binary classification\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Train the model with SGD optimizer\n",
        "model_sgd = build_model()\n",
        "model_sgd.compile(optimizer=keras.optimizers.SGD(learning_rate=0.01),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Convert target variable to integer (0 or 1) for binary crossentropy\n",
        "y_train_int = (y_train == '>50K').astype(int)\n",
        "y_val_int = (y_val == '>50K').astype(int)\n",
        "\n",
        "history_sgd = model_sgd.fit(X_train_processed, y_train_int,\n",
        "                            epochs=20,\n",
        "                            batch_size=32,\n",
        "                            validation_data=(X_val_processed, y_val_int),\n",
        "                            verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7701 - loss: 0.4756 - val_accuracy: 0.8421 - val_loss: 0.3440\n",
            "Epoch 2/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8354 - loss: 0.3533 - val_accuracy: 0.8524 - val_loss: 0.3247\n",
            "Epoch 3/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8428 - loss: 0.3327 - val_accuracy: 0.8559 - val_loss: 0.3172\n",
            "Epoch 4/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8450 - loss: 0.3286 - val_accuracy: 0.8569 - val_loss: 0.3138\n",
            "Epoch 5/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8437 - loss: 0.3296 - val_accuracy: 0.8574 - val_loss: 0.3115\n",
            "Epoch 6/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8499 - loss: 0.3227 - val_accuracy: 0.8576 - val_loss: 0.3098\n",
            "Epoch 7/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8486 - loss: 0.3239 - val_accuracy: 0.8580 - val_loss: 0.3095\n",
            "Epoch 8/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8491 - loss: 0.3255 - val_accuracy: 0.8556 - val_loss: 0.3097\n",
            "Epoch 9/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8510 - loss: 0.3185 - val_accuracy: 0.8539 - val_loss: 0.3112\n",
            "Epoch 10/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8508 - loss: 0.3179 - val_accuracy: 0.8594 - val_loss: 0.3085\n",
            "Epoch 11/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8517 - loss: 0.3180 - val_accuracy: 0.8602 - val_loss: 0.3085\n",
            "Epoch 12/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8484 - loss: 0.3225 - val_accuracy: 0.8602 - val_loss: 0.3076\n",
            "Epoch 13/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8544 - loss: 0.3118 - val_accuracy: 0.8601 - val_loss: 0.3073\n",
            "Epoch 14/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8512 - loss: 0.3181 - val_accuracy: 0.8613 - val_loss: 0.3064\n",
            "Epoch 15/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8520 - loss: 0.3168 - val_accuracy: 0.8601 - val_loss: 0.3070\n",
            "Epoch 16/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8486 - loss: 0.3214 - val_accuracy: 0.8591 - val_loss: 0.3077\n",
            "Epoch 17/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8486 - loss: 0.3158 - val_accuracy: 0.8601 - val_loss: 0.3067\n",
            "Epoch 18/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8536 - loss: 0.3153 - val_accuracy: 0.8601 - val_loss: 0.3066\n",
            "Epoch 19/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8527 - loss: 0.3184 - val_accuracy: 0.8610 - val_loss: 0.3063\n",
            "Epoch 20/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8565 - loss: 0.3081 - val_accuracy: 0.8612 - val_loss: 0.3060\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Batch Size\n",
        "1. Train the same model with different batch sizes (e.g., 1, 32, 128, 1024).\n",
        "2. Compare:\n",
        "   - Training speed\n",
        "   - Validation accuracy\n",
        "   - Test accuracy\n",
        "   - Generalization ability\n",
        "3. Which batch size leads to the **noisiest gradient updates**?\n",
        "4. Which batch size generalizes better and why?"
      ],
      "metadata": {
        "id": "Wv6ZlRldHC09"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d9ec36a",
        "outputId": "9c99ae19-3163-4d7c-c98c-80792d819242"
      },
      "source": [
        "# Train the model with batch size 1\n",
        "model_bs1 = build_model()\n",
        "model_bs1.compile(optimizer=keras.optimizers.SGD(learning_rate=0.01),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "history_bs1 = model_bs1.fit(X_train_processed, y_train_int,\n",
        "                            epochs=20,\n",
        "                            batch_size=1,\n",
        "                            validation_data=(X_val_processed, y_val_int),\n",
        "                            verbose=1)\n",
        "\n",
        "# Train the model with batch size 128\n",
        "model_bs128 = build_model()\n",
        "model_bs128.compile(optimizer=keras.optimizers.SGD(learning_rate=0.01),\n",
        "                    loss='binary_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "history_bs128 = model_bs128.fit(X_train_processed, y_train_int,\n",
        "                              epochs=20,\n",
        "                              batch_size=128,\n",
        "                              validation_data=(X_val_processed, y_val_int),\n",
        "                              verbose=1)\n",
        "\n",
        "# Train the model with batch size 1024\n",
        "model_bs1024 = build_model()\n",
        "model_bs1024.compile(optimizer=keras.optimizers.SGD(learning_rate=0.01),\n",
        "                     loss='binary_crossentropy',\n",
        "                     metrics=['accuracy'])\n",
        "\n",
        "history_bs1024 = model_bs1024.fit(X_train_processed, y_train_int,\n",
        "                                epochs=20,\n",
        "                                batch_size=1024,\n",
        "                                validation_data=(X_val_processed, y_val_int),\n",
        "                                verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m34189/34189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 3ms/step - accuracy: 0.8376 - loss: 0.3516 - val_accuracy: 0.8535 - val_loss: 0.3175\n",
            "Epoch 2/20\n",
            "\u001b[1m34189/34189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 2ms/step - accuracy: 0.8550 - loss: 0.3152 - val_accuracy: 0.8654 - val_loss: 0.3108\n",
            "Epoch 3/20\n",
            "\u001b[1m34189/34189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 2ms/step - accuracy: 0.8519 - loss: 0.3163 - val_accuracy: 0.8623 - val_loss: 0.3069\n",
            "Epoch 4/20\n",
            "\u001b[1m34189/34189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 3ms/step - accuracy: 0.8502 - loss: 0.3179 - val_accuracy: 0.8631 - val_loss: 0.3056\n",
            "Epoch 5/20\n",
            "\u001b[1m34189/34189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 3ms/step - accuracy: 0.8523 - loss: 0.3144 - val_accuracy: 0.8628 - val_loss: 0.3073\n",
            "Epoch 6/20\n",
            "\u001b[1m34189/34189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 3ms/step - accuracy: 0.8582 - loss: 0.3100 - val_accuracy: 0.8624 - val_loss: 0.3062\n",
            "Epoch 7/20\n",
            "\u001b[1m34189/34189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 3ms/step - accuracy: 0.8596 - loss: 0.3035 - val_accuracy: 0.8635 - val_loss: 0.3070\n",
            "Epoch 8/20\n",
            "\u001b[1m34189/34189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 2ms/step - accuracy: 0.8577 - loss: 0.3074 - val_accuracy: 0.8635 - val_loss: 0.3066\n",
            "Epoch 9/20\n",
            "\u001b[1m34189/34189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 3ms/step - accuracy: 0.8614 - loss: 0.3036 - val_accuracy: 0.8636 - val_loss: 0.3054\n",
            "Epoch 10/20\n",
            "\u001b[1m34189/34189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 3ms/step - accuracy: 0.8596 - loss: 0.3063 - val_accuracy: 0.8638 - val_loss: 0.3075\n",
            "Epoch 11/20\n",
            "\u001b[1m34189/34189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 3ms/step - accuracy: 0.8559 - loss: 0.3073 - val_accuracy: 0.8621 - val_loss: 0.3076\n",
            "Epoch 12/20\n",
            "\u001b[1m34189/34189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 3ms/step - accuracy: 0.8653 - loss: 0.2987 - val_accuracy: 0.8625 - val_loss: 0.3067\n",
            "Epoch 13/20\n",
            "\u001b[1m34189/34189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 2ms/step - accuracy: 0.8590 - loss: 0.3038 - val_accuracy: 0.8628 - val_loss: 0.3066\n",
            "Epoch 14/20\n",
            "\u001b[1m34189/34189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 2ms/step - accuracy: 0.8612 - loss: 0.3024 - val_accuracy: 0.8605 - val_loss: 0.3066\n",
            "Epoch 15/20\n",
            "\u001b[1m34189/34189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2ms/step - accuracy: 0.8620 - loss: 0.2948 - val_accuracy: 0.8630 - val_loss: 0.3085\n",
            "Epoch 16/20\n",
            "\u001b[1m34189/34189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 2ms/step - accuracy: 0.8627 - loss: 0.2973 - val_accuracy: 0.8627 - val_loss: 0.3058\n",
            "Epoch 17/20\n",
            "\u001b[1m34189/34189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 3ms/step - accuracy: 0.8597 - loss: 0.3031 - val_accuracy: 0.8569 - val_loss: 0.3119\n",
            "Epoch 18/20\n",
            "\u001b[1m34189/34189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2ms/step - accuracy: 0.8679 - loss: 0.2938 - val_accuracy: 0.8594 - val_loss: 0.3082\n",
            "Epoch 19/20\n",
            "\u001b[1m34189/34189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 3ms/step - accuracy: 0.8606 - loss: 0.2998 - val_accuracy: 0.8572 - val_loss: 0.3152\n",
            "Epoch 20/20\n",
            "\u001b[1m34189/34189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 3ms/step - accuracy: 0.8628 - loss: 0.2938 - val_accuracy: 0.8589 - val_loss: 0.3116\n",
            "Epoch 1/20\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6579 - loss: 0.6157 - val_accuracy: 0.7935 - val_loss: 0.4316\n",
            "Epoch 2/20\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7961 - loss: 0.4305 - val_accuracy: 0.8367 - val_loss: 0.3686\n",
            "Epoch 3/20\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8228 - loss: 0.3865 - val_accuracy: 0.8411 - val_loss: 0.3507\n",
            "Epoch 4/20\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8282 - loss: 0.3686 - val_accuracy: 0.8432 - val_loss: 0.3423\n",
            "Epoch 5/20\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8326 - loss: 0.3578 - val_accuracy: 0.8456 - val_loss: 0.3370\n",
            "Epoch 6/20\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8325 - loss: 0.3552 - val_accuracy: 0.8478 - val_loss: 0.3325\n",
            "Epoch 7/20\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8390 - loss: 0.3438 - val_accuracy: 0.8493 - val_loss: 0.3291\n",
            "Epoch 8/20\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8365 - loss: 0.3486 - val_accuracy: 0.8498 - val_loss: 0.3260\n",
            "Epoch 9/20\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8401 - loss: 0.3409 - val_accuracy: 0.8516 - val_loss: 0.3242\n",
            "Epoch 10/20\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8416 - loss: 0.3401 - val_accuracy: 0.8519 - val_loss: 0.3219\n",
            "Epoch 11/20\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8439 - loss: 0.3385 - val_accuracy: 0.8526 - val_loss: 0.3204\n",
            "Epoch 12/20\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8420 - loss: 0.3390 - val_accuracy: 0.8522 - val_loss: 0.3190\n",
            "Epoch 13/20\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8445 - loss: 0.3298 - val_accuracy: 0.8537 - val_loss: 0.3174\n",
            "Epoch 14/20\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8462 - loss: 0.3330 - val_accuracy: 0.8549 - val_loss: 0.3165\n",
            "Epoch 15/20\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8436 - loss: 0.3337 - val_accuracy: 0.8557 - val_loss: 0.3152\n",
            "Epoch 16/20\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8455 - loss: 0.3333 - val_accuracy: 0.8564 - val_loss: 0.3144\n",
            "Epoch 17/20\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8473 - loss: 0.3306 - val_accuracy: 0.8564 - val_loss: 0.3139\n",
            "Epoch 18/20\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8472 - loss: 0.3247 - val_accuracy: 0.8560 - val_loss: 0.3135\n",
            "Epoch 19/20\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8433 - loss: 0.3329 - val_accuracy: 0.8560 - val_loss: 0.3130\n",
            "Epoch 20/20\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8476 - loss: 0.3300 - val_accuracy: 0.8572 - val_loss: 0.3117\n",
            "Epoch 1/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.4776 - loss: 0.7119 - val_accuracy: 0.8004 - val_loss: 0.5934\n",
            "Epoch 2/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7545 - loss: 0.5893 - val_accuracy: 0.7774 - val_loss: 0.5271\n",
            "Epoch 3/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7661 - loss: 0.5373 - val_accuracy: 0.7756 - val_loss: 0.4916\n",
            "Epoch 4/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7667 - loss: 0.5057 - val_accuracy: 0.7778 - val_loss: 0.4681\n",
            "Epoch 5/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7718 - loss: 0.4854 - val_accuracy: 0.7811 - val_loss: 0.4496\n",
            "Epoch 6/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7754 - loss: 0.4691 - val_accuracy: 0.7905 - val_loss: 0.4338\n",
            "Epoch 7/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7807 - loss: 0.4529 - val_accuracy: 0.8006 - val_loss: 0.4201\n",
            "Epoch 8/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7870 - loss: 0.4407 - val_accuracy: 0.8094 - val_loss: 0.4081\n",
            "Epoch 9/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7968 - loss: 0.4259 - val_accuracy: 0.8186 - val_loss: 0.3978\n",
            "Epoch 10/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8024 - loss: 0.4185 - val_accuracy: 0.8246 - val_loss: 0.3888\n",
            "Epoch 11/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8092 - loss: 0.4095 - val_accuracy: 0.8318 - val_loss: 0.3811\n",
            "Epoch 12/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8125 - loss: 0.4027 - val_accuracy: 0.8363 - val_loss: 0.3746\n",
            "Epoch 13/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8127 - loss: 0.3998 - val_accuracy: 0.8382 - val_loss: 0.3692\n",
            "Epoch 14/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8199 - loss: 0.3896 - val_accuracy: 0.8395 - val_loss: 0.3646\n",
            "Epoch 15/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8201 - loss: 0.3876 - val_accuracy: 0.8406 - val_loss: 0.3608\n",
            "Epoch 16/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8243 - loss: 0.3808 - val_accuracy: 0.8403 - val_loss: 0.3575\n",
            "Epoch 17/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8241 - loss: 0.3805 - val_accuracy: 0.8415 - val_loss: 0.3547\n",
            "Epoch 18/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8263 - loss: 0.3750 - val_accuracy: 0.8422 - val_loss: 0.3523\n",
            "Epoch 19/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8239 - loss: 0.3727 - val_accuracy: 0.8429 - val_loss: 0.3502\n",
            "Epoch 20/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8264 - loss: 0.3716 - val_accuracy: 0.8436 - val_loss: 0.3484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Part 3: Overfitting and Regularization\n",
        "1. Train a large neural network (many parameters) on the dataset.\n",
        "2. Observe training vs. validation accuracy.  \n",
        "   - Do you see signs of overfitting?\n",
        "3. Apply regularization techniques:\n",
        "   - **L2 regularization**\n",
        "   - **Dropout**\n",
        "4. Compare the validation results before and after regularization.\n",
        "5. Which regularization method was more effective in reducing overfitting? Why?\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "9NDO_bUjHDz3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0343b1c",
        "outputId": "408365df-ce2d-404d-d2cf-9009aad6e710"
      },
      "source": [
        "# Define a larger neural network model\n",
        "def build_large_model():\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Dense(256, activation='relu', input_shape=(X_train_processed.shape[1],)),\n",
        "        keras.layers.Dense(128, activation='relu'),\n",
        "        keras.layers.Dense(64, activation='relu'),\n",
        "        keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Train the large model without regularization\n",
        "large_model_no_reg = build_large_model()\n",
        "large_model_no_reg.compile(optimizer='adam', # Using Adam for potentially faster convergence\n",
        "                           loss='binary_crossentropy',\n",
        "                           metrics=['accuracy'])\n",
        "\n",
        "history_large_no_reg = large_model_no_reg.fit(X_train_processed, y_train_int,\n",
        "                                              epochs=50, # Train for more epochs to observe overfitting\n",
        "                                              batch_size=32,\n",
        "                                              validation_data=(X_val_processed, y_val_int),\n",
        "                                              verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8373 - loss: 0.3428 - val_accuracy: 0.8608 - val_loss: 0.3098\n",
            "Epoch 2/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8567 - loss: 0.3102 - val_accuracy: 0.8583 - val_loss: 0.3122\n",
            "Epoch 3/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8604 - loss: 0.3036 - val_accuracy: 0.8630 - val_loss: 0.3059\n",
            "Epoch 4/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8623 - loss: 0.2929 - val_accuracy: 0.8616 - val_loss: 0.3051\n",
            "Epoch 5/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8677 - loss: 0.2863 - val_accuracy: 0.8630 - val_loss: 0.3102\n",
            "Epoch 6/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8652 - loss: 0.2894 - val_accuracy: 0.8606 - val_loss: 0.3100\n",
            "Epoch 7/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8657 - loss: 0.2841 - val_accuracy: 0.8605 - val_loss: 0.3141\n",
            "Epoch 8/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8725 - loss: 0.2735 - val_accuracy: 0.8616 - val_loss: 0.3217\n",
            "Epoch 9/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8771 - loss: 0.2607 - val_accuracy: 0.8583 - val_loss: 0.3314\n",
            "Epoch 10/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8762 - loss: 0.2554 - val_accuracy: 0.8568 - val_loss: 0.3388\n",
            "Epoch 11/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8791 - loss: 0.2501 - val_accuracy: 0.8574 - val_loss: 0.3403\n",
            "Epoch 12/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8808 - loss: 0.2452 - val_accuracy: 0.8575 - val_loss: 0.3905\n",
            "Epoch 13/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8836 - loss: 0.2400 - val_accuracy: 0.8541 - val_loss: 0.4084\n",
            "Epoch 14/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8919 - loss: 0.2273 - val_accuracy: 0.8539 - val_loss: 0.4118\n",
            "Epoch 15/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8923 - loss: 0.2242 - val_accuracy: 0.8514 - val_loss: 0.4222\n",
            "Epoch 16/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8951 - loss: 0.2181 - val_accuracy: 0.8479 - val_loss: 0.4749\n",
            "Epoch 17/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8984 - loss: 0.2107 - val_accuracy: 0.8475 - val_loss: 0.4744\n",
            "Epoch 18/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9036 - loss: 0.2026 - val_accuracy: 0.8479 - val_loss: 0.5059\n",
            "Epoch 19/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9012 - loss: 0.2084 - val_accuracy: 0.8421 - val_loss: 0.5021\n",
            "Epoch 20/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9010 - loss: 0.2016 - val_accuracy: 0.8468 - val_loss: 0.5514\n",
            "Epoch 21/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9062 - loss: 0.1909 - val_accuracy: 0.8492 - val_loss: 0.5736\n",
            "Epoch 22/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9117 - loss: 0.1839 - val_accuracy: 0.8467 - val_loss: 0.6032\n",
            "Epoch 23/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9114 - loss: 0.1861 - val_accuracy: 0.8445 - val_loss: 0.6317\n",
            "Epoch 24/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9119 - loss: 0.1830 - val_accuracy: 0.8477 - val_loss: 0.7327\n",
            "Epoch 25/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9145 - loss: 0.1802 - val_accuracy: 0.8423 - val_loss: 0.6595\n",
            "Epoch 26/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9168 - loss: 0.1716 - val_accuracy: 0.8365 - val_loss: 0.7086\n",
            "Epoch 27/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9198 - loss: 0.1680 - val_accuracy: 0.8449 - val_loss: 0.7136\n",
            "Epoch 28/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9196 - loss: 0.1674 - val_accuracy: 0.8434 - val_loss: 0.7927\n",
            "Epoch 29/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9218 - loss: 0.1629 - val_accuracy: 0.8365 - val_loss: 0.7272\n",
            "Epoch 30/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9198 - loss: 0.1692 - val_accuracy: 0.8365 - val_loss: 0.7381\n",
            "Epoch 31/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9201 - loss: 0.1645 - val_accuracy: 0.8404 - val_loss: 0.8041\n",
            "Epoch 32/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9238 - loss: 0.1553 - val_accuracy: 0.8382 - val_loss: 0.8603\n",
            "Epoch 33/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9248 - loss: 0.1562 - val_accuracy: 0.8393 - val_loss: 0.8241\n",
            "Epoch 34/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9280 - loss: 0.1566 - val_accuracy: 0.8351 - val_loss: 0.8871\n",
            "Epoch 35/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9305 - loss: 0.1481 - val_accuracy: 0.8362 - val_loss: 0.9108\n",
            "Epoch 36/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9285 - loss: 0.1486 - val_accuracy: 0.8388 - val_loss: 0.9209\n",
            "Epoch 37/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9254 - loss: 0.1526 - val_accuracy: 0.8408 - val_loss: 0.8922\n",
            "Epoch 38/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9263 - loss: 0.1494 - val_accuracy: 0.8385 - val_loss: 1.0035\n",
            "Epoch 39/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9333 - loss: 0.1386 - val_accuracy: 0.8354 - val_loss: 0.9964\n",
            "Epoch 40/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9301 - loss: 0.1450 - val_accuracy: 0.8339 - val_loss: 1.0064\n",
            "Epoch 41/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9307 - loss: 0.1423 - val_accuracy: 0.8343 - val_loss: 1.0112\n",
            "Epoch 42/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9337 - loss: 0.1383 - val_accuracy: 0.8357 - val_loss: 1.0985\n",
            "Epoch 43/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9349 - loss: 0.1363 - val_accuracy: 0.8361 - val_loss: 1.0882\n",
            "Epoch 44/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9330 - loss: 0.1401 - val_accuracy: 0.8358 - val_loss: 1.1325\n",
            "Epoch 45/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9377 - loss: 0.1327 - val_accuracy: 0.8344 - val_loss: 1.1023\n",
            "Epoch 46/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9369 - loss: 0.1322 - val_accuracy: 0.8389 - val_loss: 1.1435\n",
            "Epoch 47/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9366 - loss: 0.1368 - val_accuracy: 0.8362 - val_loss: 1.1690\n",
            "Epoch 48/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9393 - loss: 0.1248 - val_accuracy: 0.8373 - val_loss: 1.1708\n",
            "Epoch 49/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9377 - loss: 0.1309 - val_accuracy: 0.8367 - val_loss: 1.0996\n",
            "Epoch 50/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9418 - loss: 0.1241 - val_accuracy: 0.8415 - val_loss: 1.2094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d74t2UPVHKdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: Early Stopping\n",
        "1. Train the model for many epochs without early stopping.  \n",
        "   - Plot training, validation, and test curves.\n",
        "2. Train again with **early stopping** (monitor validation loss).\n",
        "3. Compare the number of epochs trained and the final validation/test accuracy.\n",
        "4. Explain how early stopping helps prevent overfitting.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "B0NQsxyYHFpy"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "7d3b2264",
        "outputId": "82eb22d5-c935-4c2f-a935-0320d877114c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training and validation accuracy and loss\n",
        "def plot_history(history, title):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title(f'{title} - Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title(f'{title} - Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Plot the history for the large model without regularization\n",
        "plot_history(history_large_no_reg, 'Large Model Without Regularization')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bba4834c",
        "outputId": "817738e3-962c-4352-db41-ca281101859e"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Train the large model with Early Stopping\n",
        "large_model_early_stopping = build_large_model() # Use the same large model structure\n",
        "large_model_early_stopping.compile(optimizer='adam',\n",
        "                                    loss='binary_crossentropy',\n",
        "                                    metrics=['accuracy'])\n",
        "\n",
        "# Define the Early Stopping callback\n",
        "early_stopping_callback = EarlyStopping(\n",
        "    monitor='val_loss', # Monitor validation loss\n",
        "    patience=10,        # Number of epochs with no improvement after which training will be stopped\n",
        "    restore_best_weights=True # Restore model weights from the epoch with the best value of the monitored quantity.\n",
        ")\n",
        "\n",
        "history_large_early_stopping = large_model_early_stopping.fit(X_train_processed, y_train_int,\n",
        "                                                            epochs=100, # Train for a large number of epochs\n",
        "                                                            batch_size=32,\n",
        "                                                            validation_data=(X_val_processed, y_val_int),\n",
        "                                                            callbacks=[early_stopping_callback], # Add the callback\n",
        "                                                            verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8381 - loss: 0.3482 - val_accuracy: 0.8606 - val_loss: 0.3072\n",
            "Epoch 2/100\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8521 - loss: 0.3132 - val_accuracy: 0.8630 - val_loss: 0.3042\n",
            "Epoch 3/100\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8608 - loss: 0.3034 - val_accuracy: 0.8612 - val_loss: 0.3094\n",
            "Epoch 4/100\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8586 - loss: 0.3029 - val_accuracy: 0.8647 - val_loss: 0.3065\n",
            "Epoch 5/100\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8658 - loss: 0.2911 - val_accuracy: 0.8597 - val_loss: 0.3089\n",
            "Epoch 6/100\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8670 - loss: 0.2873 - val_accuracy: 0.8630 - val_loss: 0.3072\n",
            "Epoch 7/100\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8693 - loss: 0.2801 - val_accuracy: 0.8609 - val_loss: 0.3134\n",
            "Epoch 8/100\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8737 - loss: 0.2733 - val_accuracy: 0.8627 - val_loss: 0.3191\n",
            "Epoch 9/100\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8748 - loss: 0.2660 - val_accuracy: 0.8580 - val_loss: 0.3374\n",
            "Epoch 10/100\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8758 - loss: 0.2602 - val_accuracy: 0.8609 - val_loss: 0.3331\n",
            "Epoch 11/100\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8821 - loss: 0.2513 - val_accuracy: 0.8571 - val_loss: 0.3489\n",
            "Epoch 12/100\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8851 - loss: 0.2434 - val_accuracy: 0.8569 - val_loss: 0.3614\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "731de567",
        "outputId": "013fcd0d-318f-4af4-de5c-3d528bc55695"
      },
      "source": [
        "from tensorflow.keras import regularizers\n",
        "\n",
        "# Train the large model with L2 regularization\n",
        "def build_large_model_l2():\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Dense(256, activation='relu', input_shape=(X_train_processed.shape[1],),\n",
        "                           kernel_regularizer=regularizers.l2(0.001)),\n",
        "        keras.layers.Dense(128, activation='relu',\n",
        "                           kernel_regularizer=regularizers.l2(0.001)),\n",
        "        keras.layers.Dense(64, activation='relu',\n",
        "                           kernel_regularizer=regularizers.l2(0.001)),\n",
        "        keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "large_model_l2 = build_large_model_l2()\n",
        "large_model_l2.compile(optimizer='adam',\n",
        "                       loss='binary_crossentropy',\n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "history_large_l2 = large_model_l2.fit(X_train_processed, y_train_int,\n",
        "                                      epochs=50,\n",
        "                                      batch_size=32,\n",
        "                                      validation_data=(X_val_processed, y_val_int),\n",
        "                                      verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.8335 - loss: 0.5203 - val_accuracy: 0.8478 - val_loss: 0.3557\n",
            "Epoch 2/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8512 - loss: 0.3440 - val_accuracy: 0.8527 - val_loss: 0.3422\n",
            "Epoch 3/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8541 - loss: 0.3337 - val_accuracy: 0.8616 - val_loss: 0.3208\n",
            "Epoch 4/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8527 - loss: 0.3294 - val_accuracy: 0.8605 - val_loss: 0.3233\n",
            "Epoch 5/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8554 - loss: 0.3231 - val_accuracy: 0.8642 - val_loss: 0.3191\n",
            "Epoch 6/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8567 - loss: 0.3209 - val_accuracy: 0.8595 - val_loss: 0.3194\n",
            "Epoch 7/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8572 - loss: 0.3206 - val_accuracy: 0.8586 - val_loss: 0.3189\n",
            "Epoch 8/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8582 - loss: 0.3204 - val_accuracy: 0.8628 - val_loss: 0.3132\n",
            "Epoch 9/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8586 - loss: 0.3142 - val_accuracy: 0.8631 - val_loss: 0.3159\n",
            "Epoch 10/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8596 - loss: 0.3149 - val_accuracy: 0.8621 - val_loss: 0.3147\n",
            "Epoch 11/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8557 - loss: 0.3201 - val_accuracy: 0.8660 - val_loss: 0.3127\n",
            "Epoch 12/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8588 - loss: 0.3195 - val_accuracy: 0.8600 - val_loss: 0.3189\n",
            "Epoch 13/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8570 - loss: 0.3192 - val_accuracy: 0.8664 - val_loss: 0.3122\n",
            "Epoch 14/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8595 - loss: 0.3128 - val_accuracy: 0.8643 - val_loss: 0.3142\n",
            "Epoch 15/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8596 - loss: 0.3148 - val_accuracy: 0.8630 - val_loss: 0.3158\n",
            "Epoch 16/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8589 - loss: 0.3142 - val_accuracy: 0.8631 - val_loss: 0.3146\n",
            "Epoch 17/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8602 - loss: 0.3110 - val_accuracy: 0.8627 - val_loss: 0.3152\n",
            "Epoch 18/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8589 - loss: 0.3122 - val_accuracy: 0.8578 - val_loss: 0.3183\n",
            "Epoch 19/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8581 - loss: 0.3164 - val_accuracy: 0.8591 - val_loss: 0.3207\n",
            "Epoch 20/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8572 - loss: 0.3127 - val_accuracy: 0.8649 - val_loss: 0.3124\n",
            "Epoch 21/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8584 - loss: 0.3117 - val_accuracy: 0.8627 - val_loss: 0.3139\n",
            "Epoch 22/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8608 - loss: 0.3109 - val_accuracy: 0.8620 - val_loss: 0.3181\n",
            "Epoch 23/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8593 - loss: 0.3096 - val_accuracy: 0.8632 - val_loss: 0.3126\n",
            "Epoch 24/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8614 - loss: 0.3096 - val_accuracy: 0.8662 - val_loss: 0.3117\n",
            "Epoch 25/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8582 - loss: 0.3147 - val_accuracy: 0.8632 - val_loss: 0.3119\n",
            "Epoch 26/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8593 - loss: 0.3124 - val_accuracy: 0.8576 - val_loss: 0.3193\n",
            "Epoch 27/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8594 - loss: 0.3135 - val_accuracy: 0.8645 - val_loss: 0.3116\n",
            "Epoch 28/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.8608 - loss: 0.3091 - val_accuracy: 0.8623 - val_loss: 0.3110\n",
            "Epoch 29/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8614 - loss: 0.3119 - val_accuracy: 0.8627 - val_loss: 0.3125\n",
            "Epoch 30/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8617 - loss: 0.3081 - val_accuracy: 0.8630 - val_loss: 0.3113\n",
            "Epoch 31/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8597 - loss: 0.3095 - val_accuracy: 0.8625 - val_loss: 0.3122\n",
            "Epoch 32/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8643 - loss: 0.3042 - val_accuracy: 0.8620 - val_loss: 0.3120\n",
            "Epoch 33/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8603 - loss: 0.3081 - val_accuracy: 0.8496 - val_loss: 0.3268\n",
            "Epoch 34/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8643 - loss: 0.3047 - val_accuracy: 0.8642 - val_loss: 0.3121\n",
            "Epoch 35/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8607 - loss: 0.3103 - val_accuracy: 0.8630 - val_loss: 0.3132\n",
            "Epoch 36/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8584 - loss: 0.3106 - val_accuracy: 0.8604 - val_loss: 0.3127\n",
            "Epoch 37/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8649 - loss: 0.3043 - val_accuracy: 0.8563 - val_loss: 0.3224\n",
            "Epoch 38/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8623 - loss: 0.3098 - val_accuracy: 0.8619 - val_loss: 0.3138\n",
            "Epoch 39/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8654 - loss: 0.3065 - val_accuracy: 0.8589 - val_loss: 0.3188\n",
            "Epoch 40/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8613 - loss: 0.3055 - val_accuracy: 0.8624 - val_loss: 0.3125\n",
            "Epoch 41/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8628 - loss: 0.3081 - val_accuracy: 0.8554 - val_loss: 0.3193\n",
            "Epoch 42/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8627 - loss: 0.3059 - val_accuracy: 0.8630 - val_loss: 0.3127\n",
            "Epoch 43/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8644 - loss: 0.3040 - val_accuracy: 0.8630 - val_loss: 0.3128\n",
            "Epoch 44/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8628 - loss: 0.3075 - val_accuracy: 0.8612 - val_loss: 0.3118\n",
            "Epoch 45/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8642 - loss: 0.3059 - val_accuracy: 0.8582 - val_loss: 0.3167\n",
            "Epoch 46/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8637 - loss: 0.3069 - val_accuracy: 0.8632 - val_loss: 0.3135\n",
            "Epoch 47/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8615 - loss: 0.3086 - val_accuracy: 0.8632 - val_loss: 0.3143\n",
            "Epoch 48/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8622 - loss: 0.3057 - val_accuracy: 0.8617 - val_loss: 0.3143\n",
            "Epoch 49/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8634 - loss: 0.3035 - val_accuracy: 0.8645 - val_loss: 0.3128\n",
            "Epoch 50/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8613 - loss: 0.3062 - val_accuracy: 0.8624 - val_loss: 0.3167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7908f12f",
        "outputId": "8600a7e0-a193-4e93-ee49-872c1f271726"
      },
      "source": [
        "# Train the large model with Dropout\n",
        "def build_large_model_dropout():\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Dense(256, activation='relu', input_shape=(X_train_processed.shape[1],)),\n",
        "        keras.layers.Dropout(0.3), # Add dropout layers\n",
        "        keras.layers.Dense(128, activation='relu'),\n",
        "        keras.layers.Dropout(0.3),\n",
        "        keras.layers.Dense(64, activation='relu'),\n",
        "        keras.layers.Dropout(0.3),\n",
        "        keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "large_model_dropout = build_large_model_dropout()\n",
        "large_model_dropout.compile(optimizer='adam',\n",
        "                            loss='binary_crossentropy',\n",
        "                            metrics=['accuracy'])\n",
        "\n",
        "history_large_dropout = large_model_dropout.fit(X_train_processed, y_train_int,\n",
        "                                                epochs=50,\n",
        "                                                batch_size=32,\n",
        "                                                validation_data=(X_val_processed, y_val_int),\n",
        "                                                verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.8273 - loss: 0.3692 - val_accuracy: 0.8604 - val_loss: 0.3098\n",
            "Epoch 2/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8480 - loss: 0.3259 - val_accuracy: 0.8561 - val_loss: 0.3146\n",
            "Epoch 3/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8538 - loss: 0.3150 - val_accuracy: 0.8619 - val_loss: 0.3078\n",
            "Epoch 4/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8594 - loss: 0.3040 - val_accuracy: 0.8636 - val_loss: 0.3064\n",
            "Epoch 5/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8574 - loss: 0.3078 - val_accuracy: 0.8647 - val_loss: 0.3066\n",
            "Epoch 6/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8584 - loss: 0.3015 - val_accuracy: 0.8650 - val_loss: 0.3056\n",
            "Epoch 7/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8600 - loss: 0.3017 - val_accuracy: 0.8619 - val_loss: 0.3060\n",
            "Epoch 8/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8629 - loss: 0.2991 - val_accuracy: 0.8571 - val_loss: 0.3127\n",
            "Epoch 9/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8620 - loss: 0.2962 - val_accuracy: 0.8550 - val_loss: 0.3153\n",
            "Epoch 10/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8652 - loss: 0.2901 - val_accuracy: 0.8630 - val_loss: 0.3142\n",
            "Epoch 11/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8646 - loss: 0.2946 - val_accuracy: 0.8612 - val_loss: 0.3097\n",
            "Epoch 12/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8661 - loss: 0.2881 - val_accuracy: 0.8589 - val_loss: 0.3118\n",
            "Epoch 13/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8707 - loss: 0.2816 - val_accuracy: 0.8560 - val_loss: 0.3192\n",
            "Epoch 14/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8700 - loss: 0.2749 - val_accuracy: 0.8609 - val_loss: 0.3126\n",
            "Epoch 15/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8697 - loss: 0.2777 - val_accuracy: 0.8586 - val_loss: 0.3214\n",
            "Epoch 16/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8722 - loss: 0.2728 - val_accuracy: 0.8580 - val_loss: 0.3226\n",
            "Epoch 17/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8776 - loss: 0.2698 - val_accuracy: 0.8557 - val_loss: 0.3208\n",
            "Epoch 18/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8739 - loss: 0.2679 - val_accuracy: 0.8600 - val_loss: 0.3338\n",
            "Epoch 19/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8723 - loss: 0.2715 - val_accuracy: 0.8587 - val_loss: 0.3220\n",
            "Epoch 20/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8732 - loss: 0.2678 - val_accuracy: 0.8608 - val_loss: 0.3528\n",
            "Epoch 21/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8719 - loss: 0.2702 - val_accuracy: 0.8569 - val_loss: 0.3418\n",
            "Epoch 22/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8763 - loss: 0.2625 - val_accuracy: 0.8598 - val_loss: 0.3321\n",
            "Epoch 23/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8771 - loss: 0.2591 - val_accuracy: 0.8541 - val_loss: 0.3578\n",
            "Epoch 24/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8761 - loss: 0.2652 - val_accuracy: 0.8582 - val_loss: 0.3543\n",
            "Epoch 25/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8775 - loss: 0.2608 - val_accuracy: 0.8516 - val_loss: 0.3394\n",
            "Epoch 26/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8786 - loss: 0.2587 - val_accuracy: 0.8561 - val_loss: 0.3384\n",
            "Epoch 27/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8803 - loss: 0.2568 - val_accuracy: 0.8523 - val_loss: 0.3469\n",
            "Epoch 28/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8807 - loss: 0.2548 - val_accuracy: 0.8569 - val_loss: 0.3471\n",
            "Epoch 29/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8801 - loss: 0.2541 - val_accuracy: 0.8564 - val_loss: 0.3512\n",
            "Epoch 30/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8795 - loss: 0.2556 - val_accuracy: 0.8597 - val_loss: 0.3501\n",
            "Epoch 31/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8829 - loss: 0.2509 - val_accuracy: 0.8564 - val_loss: 0.3533\n",
            "Epoch 32/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8824 - loss: 0.2510 - val_accuracy: 0.8590 - val_loss: 0.3742\n",
            "Epoch 33/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8842 - loss: 0.2505 - val_accuracy: 0.8591 - val_loss: 0.3741\n",
            "Epoch 34/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8795 - loss: 0.2535 - val_accuracy: 0.8593 - val_loss: 0.3651\n",
            "Epoch 35/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8821 - loss: 0.2481 - val_accuracy: 0.8553 - val_loss: 0.3771\n",
            "Epoch 36/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8851 - loss: 0.2408 - val_accuracy: 0.8583 - val_loss: 0.3828\n",
            "Epoch 37/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8852 - loss: 0.2476 - val_accuracy: 0.8545 - val_loss: 0.3745\n",
            "Epoch 38/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8828 - loss: 0.2426 - val_accuracy: 0.8569 - val_loss: 0.3680\n",
            "Epoch 39/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8847 - loss: 0.2441 - val_accuracy: 0.8574 - val_loss: 0.3782\n",
            "Epoch 40/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8869 - loss: 0.2416 - val_accuracy: 0.8553 - val_loss: 0.3778\n",
            "Epoch 41/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8845 - loss: 0.2436 - val_accuracy: 0.8548 - val_loss: 0.3932\n",
            "Epoch 42/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8886 - loss: 0.2403 - val_accuracy: 0.8534 - val_loss: 0.4026\n",
            "Epoch 43/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8846 - loss: 0.2406 - val_accuracy: 0.8552 - val_loss: 0.4042\n",
            "Epoch 44/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8835 - loss: 0.2459 - val_accuracy: 0.8565 - val_loss: 0.4059\n",
            "Epoch 45/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8904 - loss: 0.2377 - val_accuracy: 0.8539 - val_loss: 0.3887\n",
            "Epoch 46/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8877 - loss: 0.2342 - val_accuracy: 0.8559 - val_loss: 0.4020\n",
            "Epoch 47/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8914 - loss: 0.2355 - val_accuracy: 0.8575 - val_loss: 0.3883\n",
            "Epoch 48/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8848 - loss: 0.2343 - val_accuracy: 0.8574 - val_loss: 0.3870\n",
            "Epoch 49/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8876 - loss: 0.2346 - val_accuracy: 0.8567 - val_loss: 0.3940\n",
            "Epoch 50/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8887 - loss: 0.2356 - val_accuracy: 0.8565 - val_loss: 0.4014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bnqrGbCzHI2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 5: Reflection\n",
        "1. Summarize what you learned about:\n",
        "   - The role of optimizers\n",
        "   - The effect of batch size\n",
        "   - Regularization methods\n",
        "   - Early stopping\n",
        "   - Train/validation/test splits\n",
        "2. If you had to train a deep learning model on a new tabular dataset, what choices would you make for:\n",
        "   - Optimizer\n",
        "   - Batch size\n",
        "   - Regularization\n",
        "   - Early stopping\n",
        "   - Data splitting strategy  \n",
        "   and why?"
      ],
      "metadata": {
        "id": "Ix3ePqRnHHSs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f541a36"
      },
      "source": [
        "## Part 5: Reflection\n",
        "\n",
        "Based on the exercises and general deep learning principles, here's a summary of what we've learned and how we might approach a new tabular dataset:\n",
        "\n",
        "### Summary of Learnings:\n",
        "\n",
        "*   **The role of optimizers:** Optimizers are crucial for updating model weights during training to minimize the loss function. Different optimizers like SGD, SGD with Momentum, and Adam have varying convergence characteristics and can impact training speed and final performance. Adam often converges faster and can achieve better performance due to its adaptive learning rates.\n",
        "*   **The effect of batch size:** Batch size influences the trade-off between training speed, memory usage, and the noise in gradient updates. Smaller batch sizes introduce more noise, which can sometimes help in escaping local minima and improving generalization, but they also lead to slower training. Larger batch sizes provide more stable gradient updates and faster training per epoch but might get stuck in sharp local minima.\n",
        "*   **Regularization methods:** Techniques like L2 regularization and Dropout help prevent overfitting by adding penalties to the model complexity (L2) or randomly dropping units during training (Dropout). This encourages the model to learn more robust and generalizable features.\n",
        "*   **Early stopping:** Early stopping is a form of regularization that monitors the model's performance on a validation set and stops training when the performance starts to degrade (indicating overfitting). This prevents the model from learning the training data too well and losing generalization ability.\n",
        "*   **Train/validation/test splits:** Splitting the data into distinct sets for training, validation, and testing is essential for evaluating model performance accurately and avoiding overfitting. The training set is used for model training, the validation set for hyperparameter tuning and monitoring during training (like early stopping), and the test set for a final, unbiased evaluation of the trained model's performance on unseen data.\n",
        "\n",
        "### Choices for a New Tabular Dataset:\n",
        "\n",
        "If training a deep learning model on a new tabular dataset, here are some initial choices I would make and why:\n",
        "\n",
        "*   **Optimizer:** I would likely start with **Adam**. Adam is generally a good default optimizer for many deep learning tasks, including those with tabular data. Its adaptive learning rates often lead to faster convergence and good performance without extensive manual tuning. However, I would also consider experimenting with other optimizers like SGD with Momentum or potentially more advanced optimizers if Adam doesn't yield satisfactory results.\n",
        "*   **Batch size:** I would start with a moderate batch size, such as **32 or 64**. This provides a reasonable balance between training speed and the noise in gradient updates. Larger batch sizes could be explored for faster training if computational resources allow, while smaller batch sizes might be considered if regularization is proving insufficient or if the dataset is very noisy.\n",
        "*   **Regularization:** I would incorporate both **L2 regularization and Dropout**. These are effective and commonly used regularization techniques for neural networks. I would apply L2 regularization to the dense layers and add Dropout layers after activation functions. The specific regularization strengths (L2 lambda value) and dropout rates would be treated as hyperparameters to be tuned during validation.\n",
        "*   **Early stopping:** I would definitely use **Early Stopping**. This is a simple yet powerful technique to prevent overfitting and find the optimal number of training epochs. I would monitor the validation loss and set a reasonable patience value (e.g., 10-20 epochs) to stop training if the validation loss does not improve. Restoring the best weights is also crucial to get the model with the best validation performance.\n",
        "*   **Data splitting strategy:** The **70/15/15 split** for training, validation, and testing used in this assignment is a reasonable starting point for many datasets. This provides sufficient data for training, a dedicated set for monitoring and tuning, and a separate set for final evaluation. However, the optimal split can depend on the dataset size. For very large datasets, a smaller validation/test split might be sufficient, while for smaller datasets, techniques like k-fold cross-validation on the training set might be considered for more robust evaluation during development.\n",
        "\n",
        "These would be my initial choices, but it's important to remember that hyperparameter tuning and experimentation are crucial steps in finding the best configuration for any specific dataset and task."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zj8KFZ2LGsuQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}